{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Iiikn3a5xYsR"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima as pm\n",
    "import math\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller, pacf, acf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval in minutes\n",
    "interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_data = pd.read_csv(\"anon_quik_dec_23.csv\")\n",
    "jan_data = pd.read_csv(\"anon_quik_jan_24.csv\")\n",
    "feb_data = pd.read_csv(\"anon_quik_feb_24.csv\")\n",
    "\n",
    "combined_data = pd.concat([dec_data, jan_data, feb_data], ignore_index=True)\n",
    "\n",
    "combined_data['order_received_timestamp'] = pd.to_datetime(combined_data['order_received_timestamp'])\n",
    "combined_data = combined_data.sort_values('order_received_timestamp')\n",
    "\n",
    "merchant_ids = combined_data[['merchant_id']].drop_duplicates()\n",
    "merchant_ids['seq_id'] = ['merchant' + str(i + 1) for i in range(len(merchant_ids))]\n",
    "print(merchant_ids)\n",
    "\n",
    "combined_data['Timestamp'] = combined_data['order_received_timestamp'].dt.floor(f'{interval}min')\n",
    "\n",
    "demand_per_merchant = combined_data.groupby(['merchant_id', 'Timestamp']).size().reset_index(name='Orders')\n",
    "\n",
    "demand_per_merchant = demand_per_merchant.merge(merchant_ids, on='merchant_id').drop(columns=['merchant_id'])\n",
    "demand_per_merchant = demand_per_merchant.rename(columns={'seq_id': 'merchant_id'}).sort_values('Timestamp')\n",
    "\n",
    "print(demand_per_merchant.describe())\n",
    "\n",
    "dataframes = {merchant_id: df.drop(columns=['merchant_id']) for merchant_id, df in demand_per_merchant.groupby('merchant_id')}\n",
    "\n",
    "def fill_missing_intervals(merchant_df, interval, start_date, end_date):\n",
    "    full_timestamps = pd.date_range(start=start_date, end=end_date, freq=f'{interval}min')\n",
    "    full_df = pd.DataFrame({'Timestamp': full_timestamps})\n",
    "\n",
    "    merchant_df['Timestamp'] = pd.to_datetime(merchant_df['Timestamp'])\n",
    "    full_df['Timestamp'] = pd.to_datetime(full_df['Timestamp'])\n",
    "\n",
    "    merchant_df = pd.merge(full_df, merchant_df, on='Timestamp', how='left').fillna(0)\n",
    "\n",
    "    return merchant_df\n",
    "\n",
    "last_vals_dec = {}\n",
    "last_vals_jan = {}\n",
    "\n",
    "for i, (merchant_id, merchant_df) in enumerate(dataframes.items(), start=1):\n",
    "    merchant_df = fill_missing_intervals(merchant_df, interval, \"2023-12-01 00:10:00\", \"2024-02-29 23:50:00\")\n",
    "\n",
    "    last_order_dec = merchant_df.loc[merchant_df['Timestamp'] == \"2023-12-31 23:50:00\", 'Orders'].values[0] if not merchant_df.loc[merchant_df['Timestamp'] == \"2023-12-31 23:50:00\", 'Orders'].empty else 0\n",
    "    last_order_jan = merchant_df.loc[merchant_df['Timestamp'] == \"2024-01-31 23:50:00\", 'Orders'].values[0] if not merchant_df.loc[merchant_df['Timestamp'] == \"2024-01-31 23:50:00\", 'Orders'].empty else 0\n",
    "    last_order_feb = merchant_df.loc[merchant_df['Timestamp'] == \"2024-02-29 23:50:00\", 'Orders'].values[0] if not merchant_df.loc[merchant_df['Timestamp'] == \"2024-02-29 23:50:00\", 'Orders'].empty else 0\n",
    "\n",
    "    # merchant_df['Orders'] = merchant_df['Orders'].shift(1, fill_value=0)\n",
    "\n",
    "    merchant_df.loc[merchant_df['Timestamp'] == \"2024-01-01 00:00:00\", 'Orders'] = last_order_dec\n",
    "    \n",
    "    merchant_df.loc[merchant_df['Timestamp'] == \"2024-02-01 00:00:00\", 'Orders'] = last_order_jan\n",
    "\n",
    "    last_row_march = pd.DataFrame({\n",
    "        'Timestamp': ['2024-03-01 00:00:00'],\n",
    "        'Orders': [last_order_feb]\n",
    "    })\n",
    "    \n",
    "    merchant_df = pd.concat([merchant_df, last_row_march], ignore_index=True)\n",
    "    \n",
    "    merchant_df.to_csv(f\"{merchant_id}_{interval}_quik.csv\", index=False)\n",
    "\n",
    "print(\"Data combined and processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant = \"merchant7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Zxi5M9Crxbd3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{merchant}_{interval}_quik.csv', index_col='Timestamp', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "WngZBJa4xcZT",
    "outputId": "322d054a-cdab-4bd0-8dee-0040ead02d36"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogOrders'] = np.log(np.where(df['Orders'] == 0, 1, df['Orders']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QfOxtSZ3xene"
   },
   "outputs": [],
   "source": [
    "new_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq=str(interval)+'min')\n",
    "df = df.reindex(new_index)\n",
    "\n",
    "Ntest = int(len(df) / 5)\n",
    "train = df.iloc[:-Ntest]\n",
    "test = df.iloc[-Ntest:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df.Orders, lags=30, alpha=0.05)\n",
    "plt.title('Autocorrelation')\n",
    "plt.xlabel('Number of lags')\n",
    "plt.ylabel('correlation')\n",
    "plt.savefig(f'{merchant}_{interval}_acf_quik.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_vals, confint = acf(df.Orders, nlags=len(df), alpha=0.05)\n",
    "print(\"ACF Values:\", acf_vals)\n",
    "print(\"Confidence Intervals:\", confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df.Orders, ax=plt.gca(), lags=20, alpha=0.05)\n",
    "plt.title('Partial Autocorrelation')\n",
    "plt.xlabel('Number of lags')\n",
    "plt.ylabel('correlation')\n",
    "plt.savefig(f'{merchant}_{interval}_pacf_quik.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_vals, confint = pacf(df.Orders, nlags=math.floor(len(df)/2 - 1), alpha=0.05)\n",
    "print(\"PACF Values:\", pacf_vals)\n",
    "print(\"Confidence Intervals:\", confint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6ilik6rJMVo"
   },
   "source": [
    "# SARIMA(p, d, q) x (P, D, Q, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "fft_vals = np.fft.fft(df.Orders)\n",
    "freqs = np.fft.fftfreq(len(fft_vals), d=1.0)\n",
    "\n",
    "mags = np.abs(fft_vals)\n",
    "\n",
    "pos_freqs = freqs[freqs > 0]\n",
    "pos_mags = mags[freqs > 0]\n",
    "\n",
    "peaks, _ = find_peaks(pos_mags, height=0.1 * np.max(pos_mags))\n",
    "\n",
    "peak_freqs = pos_freqs[peaks]\n",
    "peak_periods = 1 / peak_freqs\n",
    "\n",
    "for i, peak_freq in enumerate(peak_freqs):\n",
    "    print(peak_periods[i], pos_mags[peaks[i]])\n",
    "\n",
    "plt.plot(1 / pos_freqs, pos_mags)\n",
    "plt.xlim([0, 200])\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Fourier Transform')\n",
    "plt.savefig(f'{merchant}_{interval}_peaks_quik.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_periods.sort()\n",
    "m = round(peak_periods[-1])\n",
    "print(\"m =\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal period = 24 x 60 / 15 = 96\n",
    "m = int(24 * 60 / interval)\n",
    "print(\"m =\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonalities = np.delete(peak_periods, -1)\n",
    "seasonalities = np.round(seasonalities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3I5Dvi8Jpzz"
   },
   "source": [
    "## I(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Orders'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(df['Orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 2 return values are test-statistic and p-value\n",
    "# https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf(x):\n",
    "  res = adfuller(x)\n",
    "  print(\"Test statistic:\", res[0])\n",
    "  print(\"P-value:\", res[1])\n",
    "  if res[1] < 0.05:\n",
    "    print(\"Stationary\")\n",
    "  else:\n",
    "    print(\"Non-Stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf(df['Orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLPPSDGaJTSJ",
    "outputId": "c0f93a70-f7a1-472c-d39b-f48f53569944"
   },
   "outputs": [],
   "source": [
    "# by default the time series is assumed to be stationary\n",
    "d = 0\n",
    "res = adfuller(df['Orders'])\n",
    "\n",
    "\n",
    "while res[1] > 0.05:\n",
    "    d += 1\n",
    "    df['Orders'] = df['Orders'].diff().dropna()\n",
    "    res = adfuller(df['Orders'])\n",
    "\n",
    "print(\"d =\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "def kpss(x):\n",
    "    res = sm.tsa.kpss(x, regression='ct') \n",
    "    print(\"Test statistic:\", res[0])\n",
    "    print(\"P-value:\", res[1])\n",
    "    if res[1] > 0.05:\n",
    "        print(\"Stationary\")\n",
    "    else:\n",
    "        print(\"Non-Stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss(df['Orders'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "s5wnHQxhHCod"
   },
   "outputs": [],
   "source": [
    "# time series has a steady seasonal pattern over time\n",
    "D = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knUIG1_GGDzu"
   },
   "source": [
    "## AR(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5m7AYlfrCzAM",
    "outputId": "a269cc0e-faec-4261-ade2-7ffd2404c5d4"
   },
   "outputs": [],
   "source": [
    "p = 0\n",
    "for i in range(len(pacf_vals)):\n",
    "  if (pacf_vals[i] - 2/np.sqrt(len(df['Orders']))) > 0:\n",
    "    continue\n",
    "  else:\n",
    "    p = i-2\n",
    "    break\n",
    "\n",
    "print(\"p =\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoVmn840KJvs",
    "outputId": "83bc4ff3-b8ca-4f6b-d840-0233a8a216b0"
   },
   "outputs": [],
   "source": [
    "P = []\n",
    "\n",
    "if pacf_vals[m] > 0:\n",
    "  P = [1, 2]\n",
    "else:\n",
    "  P = [0]\n",
    "\n",
    "print(\"P =\", P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = []\n",
    "\n",
    "if acf_vals[m] > 0:\n",
    "  Q = [0]\n",
    "else:\n",
    "  Q = [1, 2]\n",
    "\n",
    "print(\"Q =\", Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df.Orders, lags=math.floor(len(df)/2 - 1), alpha=0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import MSTL\n",
    "\n",
    "res = MSTL(train['Orders'], periods=([48, 72])).fit()\n",
    "res.plot()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = res.trend\n",
    "seasonal = res.seasonal\n",
    "residual = res.resid\n",
    "\n",
    "# seasonals = pd.DataFrame()*2\n",
    "# for i in range(len(seasonalities)):\n",
    "#     seasonals[i] = 'seasonal_'+str(seasonalities[i])\n",
    "\n",
    "exog = pd.concat([pd.DataFrame(['seasonal_48']), pd.DataFrame(['seasonal_72'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data['Feature'] = exog.columns\n",
    "# vif_data['VIF'] = [variance_inflation_factor(exog.values, i) for i in range(exog.shape[1])]\n",
    "# print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = MSTL(test['Orders'], periods=(48, 72)).fit()\n",
    "res_test.plot()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_test = res_test.trend\n",
    "seasonal_test = res_test.seasonal\n",
    "residual_test = res_test.resid\n",
    "\n",
    "exog_test = pd.concat([pd.DataFrame(['seasonal_48']), pd.DataFrame(['seasonal_72'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkWzNoBtGewG"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fourier_terms(t, period, order):\n",
    "#     x = 2 * np.pi * (t / period)\n",
    "#     return np.column_stack([np.cos(x * i) for i in range(1, order+1)] +\n",
    "#                            [np.sin(x * i) for i in range(1, order+1)])\n",
    "\n",
    "# t = np.arange(len(train[\"Orders\"]))\n",
    "# # fourier_32 = fourier_terms(t, 32, order=1)\n",
    "# fourier_48 = fourier_terms(t, 48, order=2)\n",
    "# # exog = np.column_stack((fourier_32, fourier_48))\n",
    "# exog = fourier_48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(exog, i) for i in range(exog.shape[1])]\n",
    "# vif_data[\"Feature\"] = [f'Fourier_term_{i}' for i in range(exog.shape[1])]\n",
    "# print(vif_data)\n",
    "print(exog.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train['Orders'],\n",
    "                order=(p, d, 8),\n",
    "                seasonal_order=(P[1], D, Q[0], m),\n",
    "                exog=exog,\n",
    "                trend='ct',\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fourier_terms(t, period, order):\n",
    "#     x = 2 * np.pi * (t / period)\n",
    "#     return np.column_stack([np.cos(x * i) for i in range(1, order+1)] +\n",
    "#                            [np.sin(x * i) for i in range(1, order+1)])\n",
    "\n",
    "# t = np.arange(len(train[\"Orders\"]))\n",
    "# # fourier_32 = fourier_terms(t, 32, order=1)\n",
    "# fourier_48 = fourier_terms(t, 48, order=2)\n",
    "# # exog = np.column_stack((fourier_32, fourier_48))\n",
    "# exog = fourier_48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQzQw4olGuW4"
   },
   "source": [
    "# Static Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "FjjyyhDHZCtF"
   },
   "outputs": [],
   "source": [
    "forecast = results.get_forecast(steps=Ntest, exog=exog_test)\n",
    "test_pred = forecast.predicted_mean\n",
    "confint = forecast.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4-Mdl-PyKr2"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(test.index, test['Orders'], label='data')\n",
    "ax.plot(test.index, test_pred, label='forecast')\n",
    "ax.fill_between(test.index, \\\n",
    "                confint.iloc[:,0], confint.iloc[:,1], \\\n",
    "                color='red', alpha=0.3)\n",
    "ax.legend();\n",
    "plt.savefig(f'{merchant}_{interval}_out_of_sample_quik.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = results.get_prediction(start=0, end=-1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "ax.plot(df.index, df['Orders'], label='data')\n",
    "ax.plot(train.index, train_pred.predicted_mean, label='fitted')\n",
    "ax.plot(test.index, test_pred, label='forecast')\n",
    "ax.fill_between(test.index, \\\n",
    "                confint.iloc[:,0], confint.iloc[:,1], \\\n",
    "                color='red', alpha=0.3)\n",
    "ax.legend();\n",
    "plt.savefig(f'{merchant}_{interval}_quik.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df.LogOrders, lags=50, alpha=0.05)\n",
    "plt.title('Autocorrelation')\n",
    "plt.xlabel('Number of lags')\n",
    "plt.ylabel('correlation')\n",
    "plt.savefig(f'{merchant}_{interval}_log_acf_quik.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_vals, confint = acf(df.LogOrders, nlags=len(df), alpha=0.05)\n",
    "print(\"ACF Values:\", acf_vals)\n",
    "print(\"Confidence Intervals:\", confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df.LogOrders, ax=plt.gca(), lags=20, alpha=0.05)\n",
    "plt.title('Partial Autocorrelation')\n",
    "plt.xlabel('Number of lags')\n",
    "plt.ylabel('correlation')\n",
    "plt.savefig(f'{merchant}_{interval}_log_pacf_quik.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogOrders'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_vals, confint = pacf(df.LogOrders, nlags=math.floor(len(df)/2 - 1), alpha=0.05)\n",
    "print(\"PACF Values:\", pacf_vals)\n",
    "print(\"Confidence Intervals:\", confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_vals = np.fft.fft(df.LogOrders)\n",
    "freqs = np.fft.fftfreq(len(fft_vals), d=1.0)\n",
    "\n",
    "mags = np.abs(fft_vals)\n",
    "\n",
    "pos_freqs = freqs[freqs > 0]\n",
    "pos_mags = mags[freqs > 0]\n",
    "\n",
    "peak_idx = np.argmax(pos_mags)\n",
    "peak_freq = pos_freqs[peak_idx]\n",
    "peak_period = 1 / peak_freq if peak_freq != 0 else np.nan\n",
    "\n",
    "print(f\"Peak Period: {peak_period}\")\n",
    "\n",
    "plt.plot(1 / pos_freqs, pos_mags)\n",
    "plt.xlim([0, 150])\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Fourier Transform')\n",
    "plt.savefig(f'{merchant}_{interval}_ft_quik.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = round(peak_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(df['LogOrders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf(df['LogOrders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss(df['LogOrders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0\n",
    "for i in range(len(pacf_vals)):\n",
    "  if (pacf_vals[i] - 2/np.sqrt(len(df['Orders']))) > 0:\n",
    "    continue\n",
    "  else:\n",
    "    p = i-2\n",
    "    break\n",
    "\n",
    "print(\"p =\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "\n",
    "if acf_vals[m] > 0:\n",
    "  P = [1, 2]\n",
    "else:\n",
    "  P = [0]\n",
    "\n",
    "print(\"P =\", P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = []\n",
    "\n",
    "if acf_vals[m] > 0:\n",
    "  Q = [0]\n",
    "else:\n",
    "  Q = [1, 2]\n",
    "\n",
    "print(\"Q =\", Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0\n",
    "logmodel = SARIMAX(train['LogOrders'],\n",
    "                order=(p, d, 8),\n",
    "                seasonal_order=(P[1]+1, D, 1, m),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logmodel.fit(maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_log = results.get_forecast(steps=Ntest)\n",
    "test_pred_log = forecast_log.predicted_mean\n",
    "confint_log = forecast_log.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(test.index, test['LogOrders'], label='data')\n",
    "ax.plot(test.index, test_pred_log, label='forecast')\n",
    "ax.fill_between(test.index, \\\n",
    "                confint_log.iloc[:,0], confint_log.iloc[:,1], \\\n",
    "                color='red', alpha=0.3)\n",
    "ax.legend();\n",
    "plt.savefig(f'{merchant}_{interval}_log_out_of_sample_quik.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_log = results.get_prediction(start=0, end=-1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(df.index, df['LogOrders'], label='data')\n",
    "ax.plot(train.index, train_pred_log.predicted_mean, label='fitted')\n",
    "ax.plot(test.index, test_pred_log, label='forecast')\n",
    "ax.fill_between(test.index, \\\n",
    "                confint_log.iloc[:,0], confint_log.iloc[:,1], \\\n",
    "                color='red', alpha=0.3)\n",
    "ax.legend();\n",
    "plt.savefig(f'{merchant}_{interval}_log_quik.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "t3Y4J0boyXMT"
   },
   "outputs": [],
   "source": [
    "### forecast RMSE\n",
    "def rmse(t, y):\n",
    "  return np.sqrt(np.mean(t - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r918YUR9yYR3"
   },
   "outputs": [],
   "source": [
    "print(\"Non-logged RMSE:\", rmse(test['Orders'], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logged RMSE:\", rmse(test['Orders'], np.exp(test_pred_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-logged RMSE:\", rmse(train['Orders'], train_pred.predicted_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logged RMSE:\", rmse(train['Orders'], np.exp(train_pred_log.predicted_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "### forecast MSE\n",
    "def mse(t, y):\n",
    "  return (np.mean(t - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-logged MSE:\", mse(test['Orders'], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logged MSE:\", mse(test['Orders'], np.exp(test_pred_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-logged MSE:\", mse(train['Orders'], train_pred.predicted_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logged MSE:\", mse(train['Orders'], np.exp(train_pred_log.predicted_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "### forecast MAE\n",
    "def mae(t, y):\n",
    "  return np.mean(np.abs(t - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-logged MAE:\", mae(test['Orders'], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logged MAE:\", mae(test['Orders'], np.exp(test_pred_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-logged MAE:\", mae(train['Orders'], train_pred.predicted_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logged MAE:\", mae(train['Orders'], np.exp(train_pred_log.predicted_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theil's U-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast Theil's U-statistic\n",
    "def ustatistic(t, y):\n",
    "    num = np.sum((t - y)**2)\n",
    "    den = np.sum((t - np.mean(t))**2)\n",
    "    return np.sqrt(num / den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-logged Theil's U-statistic:\", ustatistic(test['Orders'], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logged Theil's U-statistic:\", ustatistic(test['Orders'], np.exp(test_pred_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-logged Theil's U-statistic:\", ustatistic(train['Orders'], train_pred.predicted_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logged Theil's U-statistic:\", ustatistic(train['Orders'], np.exp(train_pred_log.predicted_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = results.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(residuals.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardized Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "standardized_residuals = (residuals - residuals.mean()) / residuals.std()\n",
    "plt.plot(standardized_residuals, label='Standardized Residuals')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Standardized Residuals')\n",
    "plt.legend()\n",
    "plt.savefig(f'{merchant}_{interval}_standardized_residuals_quik.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample ACF of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plot_acf(residuals, lags=96, ax=plt.gca())\n",
    "plt.title('Sample ACF of Residuals')\n",
    "plt.xlabel('Number of lags')\n",
    "plt.ylabel('correlation')\n",
    "plt.savefig(f'{merchant}_{interval}_residuals_acf_quik.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Q-Q Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Normal Q-Q Plot')\n",
    "plt.savefig(f'{merchant}_{interval}_normal_qq_quik.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Statistic P-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "ljung_box_test = acorr_ljungbox(residuals, lags=100, return_df=True)\n",
    "print(ljung_box_test)\n",
    "\n",
    "plt.plot(ljung_box_test.index, ljung_box_test['lb_pvalue'], marker='o', color='green')\n",
    "plt.axhline(y=0.05, color='red', linestyle='--')\n",
    "plt.title('Ljung-Box p-values')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('p-value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p_value = shapiro(residuals)\n",
    "print(f'Shapiro-Wilk Test: Statistics={stat}, p-value={p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Durbin-Watson Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "dw_statistic = durbin_watson(residuals)\n",
    "\n",
    "print('Durbin-Watson statistic:', dw_statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f'{merchant}_{interval}_quik.txt'\n",
    "\n",
    "with open(filepath, 'a') as file:\n",
    "    file.write(results.summary().as_text())\n",
    "    file.write('\\n')\n",
    "    file.write(f\"Non-logged Test RMSE: {rmse(test['Orders'], test_pred)}\\n\")\n",
    "    file.write(f\"Non-logged Train RMSE: {rmse(train['Orders'], train_pred.predicted_mean)}\\n\")\n",
    "    file.write('\\n')\n",
    "    file.write(f\"Non-logged Test MSE: {mse(test['Orders'], test_pred)}\\n\")\n",
    "    file.write(f\"Non-logged Train MSE: {mse(train['Orders'], train_pred.predicted_mean)}\\n\")\n",
    "    file.write('\\n')\n",
    "    file.write(f\"Non-logged Test MAE: {mae(test['Orders'], test_pred)}\\n\")\n",
    "    file.write(f\"Non-logged Train MAE: {mae(train['Orders'], train_pred.predicted_mean)}\\n\")\n",
    "    file.write('\\n')\n",
    "    file.write(f\"Non-logged Test Theil's U-statistic: {ustatistic(test['Orders'], test_pred)}\\n\")\n",
    "    file.write(f\"Non-logged Train Theil's U-statistic: {ustatistic(train['Orders'], train_pred.predicted_mean)}\\n\")\n",
    "    file.write('\\n')\n",
    "    file.write(f\"Durban-Watson statistic: {dw_statistic}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "wp2dF2VcHomc"
   ],
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
